{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unlimited-affiliation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk.tokenize as nt\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "important-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tagging(sentence, word):\n",
    "    ss = nt.sent_tokenize(sentence)\n",
    "    tokenized_sent = [nt.word_tokenize(sent) for sent in ss]\n",
    "    tags = [nltk.pos_tag(sent) for sent in tokenized_sent]\n",
    "    print(tags)\n",
    "    ret_tag = ''\n",
    "    for tag in tags[0]:\n",
    "        if tag[0] == word:\n",
    "            ret_tag = tag[1]\n",
    "    print(ret_tag)\n",
    "    return ret_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "classical-craft",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('On', 'IN'), ('an', 'DT'), ('ugly', 'JJ'), ('baseline', 'NN'), (',', ','), ('the', 'DT'), ('Spurs', 'NNP'), ('deal', 'NN'), ('did', 'VBD'), ('little', 'JJ'), ('to', 'TO'), ('change', 'VB'), ('that', 'DT'), ('picture', 'NN'), ('.', '.')]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tagging('On an ugly baseline, the Spurs deal did little to change that picture.', 'NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "hazardous-cooler",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_article = \"[[On]] an ugly baseline, the Spurs deal did little to [[change]] that picture. THE FINAL [[SCORE]] Temple made nine threes in the first quarter and came close to doubling its game - high [[run]]. [[The]] Hawks pulled within eight points at the end of regulation, then went on a [[21]] - 4 run to seize a 53 - 46 lead. Temple's lead [[shrunk]] to only four on a jumper by Johnson with 1 : 21 to play in the first quarter. The Hawks took the [[lead]] by three in the first quarter, 66 - [[62]] on Johnson's layup with 5 : 04 to play, and outscored Temple seven - to - [[two]] in the period. [[At]] the time of the halftime [[score]], Temple had more points ( 66 ) than Goldenberg ( 55 ).\"\n",
    "before_sent_list = sent_tokenize(before_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "apart-content",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[[On]] an ugly baseline, the Spurs deal did little to [[change]] that picture.', 'THE FINAL [[SCORE]] Temple made nine threes in the first quarter and came close to doubling its game - high [[run]].', '[[The]] Hawks pulled within eight points at the end of regulation, then went on a [[21]] - 4 run to seize a 53 - 46 lead.', \"Temple's lead [[shrunk]] to only four on a jumper by Johnson with 1 : 21 to play in the first quarter.\", \"The Hawks took the [[lead]] by three in the first quarter, 66 - [[62]] on Johnson's layup with 5 : 04 to play, and outscored Temple seven - to - [[two]] in the period.\", '[[At]] the time of the halftime [[score]], Temple had more points ( 66 ) than Goldenberg ( 55 ).']\n"
     ]
    }
   ],
   "source": [
    "print(before_sent_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "processed-watch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('On', 'IN'), ('an', 'DT'), ('ugly', 'JJ'), ('baseline', 'NN'), (',', ','), ('the', 'DT'), ('Spurs', 'NNP'), ('deal', 'NN'), ('did', 'VBD'), ('little', 'JJ'), ('to', 'TO'), ('change', 'VB'), ('that', 'DT'), ('picture', 'NN'), ('.', '.')]]\n",
      "\n",
      "\n",
      "[[('THE', 'DT'), ('FINAL', 'NNP'), ('SCORE', 'NNP'), ('Temple', 'NNP'), ('made', 'VBD'), ('nine', 'CD'), ('threes', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('first', 'JJ'), ('quarter', 'NN'), ('and', 'CC'), ('came', 'VBD'), ('close', 'RB'), ('to', 'TO'), ('doubling', 'VBG'), ('its', 'PRP$'), ('game', 'NN'), ('-', ':'), ('high', 'JJ'), ('run', 'NN'), ('.', '.')]]\n",
      "\n",
      "\n",
      "[[('The', 'DT'), ('Hawks', 'NNP'), ('pulled', 'VBD'), ('within', 'IN'), ('eight', 'CD'), ('points', 'NNS'), ('at', 'IN'), ('the', 'DT'), ('end', 'NN'), ('of', 'IN'), ('regulation', 'NN'), (',', ','), ('then', 'RB'), ('went', 'VBD'), ('on', 'IN'), ('a', 'DT'), ('21', 'CD'), ('-', ':'), ('4', 'CD'), ('run', 'NN'), ('to', 'TO'), ('seize', 'VB'), ('a', 'DT'), ('53', 'CD'), ('-', ':'), ('46', 'CD'), ('lead', 'NN'), ('.', '.')]]\n",
      "\n",
      "\n",
      "[[('Temple', 'NNP'), (\"'s\", 'POS'), ('lead', 'JJ'), ('shrunk', 'NN'), ('to', 'TO'), ('only', 'RB'), ('four', 'CD'), ('on', 'IN'), ('a', 'DT'), ('jumper', 'NN'), ('by', 'IN'), ('Johnson', 'NNP'), ('with', 'IN'), ('1', 'CD'), (':', ':'), ('21', 'CD'), ('to', 'TO'), ('play', 'VB'), ('in', 'IN'), ('the', 'DT'), ('first', 'JJ'), ('quarter', 'NN'), ('.', '.')]]\n",
      "\n",
      "\n",
      "[[('The', 'DT'), ('Hawks', 'NNP'), ('took', 'VBD'), ('the', 'DT'), ('lead', 'NN'), ('by', 'IN'), ('three', 'CD'), ('in', 'IN'), ('the', 'DT'), ('first', 'JJ'), ('quarter', 'NN'), (',', ','), ('66', 'CD'), ('-', ':'), ('62', 'CD'), ('on', 'IN'), ('Johnson', 'NNP'), (\"'s\", 'POS'), ('layup', 'NN'), ('with', 'IN'), ('5', 'CD'), (':', ':'), ('04', 'CD'), ('to', 'TO'), ('play', 'VB'), (',', ','), ('and', 'CC'), ('outscored', 'VBD'), ('Temple', 'NNP'), ('seven', 'CD'), ('-', ':'), ('to', 'TO'), ('-', ':'), ('two', 'CD'), ('in', 'IN'), ('the', 'DT'), ('period', 'NN'), ('.', '.')]]\n",
      "\n",
      "\n",
      "[[('At', 'IN'), ('the', 'DT'), ('time', 'NN'), ('of', 'IN'), ('the', 'DT'), ('halftime', 'NN'), ('score', 'NN'), (',', ','), ('Temple', 'NNP'), ('had', 'VBD'), ('more', 'RBR'), ('points', 'NNS'), ('(', '('), ('66', 'CD'), (')', ')'), ('than', 'IN'), ('Goldenberg', 'NNP'), ('(', '('), ('55', 'CD'), (')', ')'), ('.', '.')]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in before_sent_list:\n",
    "    clean_sen = re.sub('[\\[\\]]', '', sent)\n",
    "    print(pos_tagging(clean_sen, ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "convertible-flesh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Hotswapp and me shared a pleasant laugh. \" Before you shed you can have my guide, \" I reminded. \" No, you will be surprised, Erika. \" Erika nodded. Finally, an hour or two later, my hands are in the palm of the hot gas, easing off his foreskin with steady four fingers and quickly removing it. I told him to shut up. I rolled my aching ass at him and he backed away, laughing at my weakness. I awkwardly kneeled down so that the gray glass domino shaped scratch had good access to my clit. I simply asked him to try me, calmly saying \" Okay \"... and to come back and tell me his names, how he had met me, etc. Once he was standing still again, I lowered myself in his lap. He says he wants to do it, but my one strong suggestion was to wait for him to come back with\n",
      "['The Hotswapp and me shared a pleasant laugh. \"', 'Before you shed you can have my guide, \" I reminded. \"', 'No, you will be surprised, Erika. \"', 'Erika nodded.', 'Finally, an hour or two later, my hands are in the palm of the hot gas, easing off his foreskin with steady four fingers and quickly removing it.', 'I told him to shut up.', 'I rolled my aching ass at him and he backed away, laughing at my weakness.', 'I awkwardly kneeled down so that the gray glass domino shaped scratch had good access to my clit.', 'I simply asked him to try me, calmly saying \" Okay \"... and to come back and tell me his names, how he had met me, etc.', 'Once he was standing still again, I lowered myself in his lap.', 'He says he wants to do it, but my one strong suggestion was to wait for him to come back with']\n",
      "[['The', 'Hotswapp', 'and', 'me', 'shared', 'a', 'pleasant', 'laugh.', '\"'], ['Before', 'you', 'shed', 'you', 'can', 'have', 'my', 'guide,', '\"', 'I', 'reminded.', '\"'], ['No,', 'you', 'will', 'be', 'surprised,', 'Erika.', '\"'], ['Erika', 'nodded.'], ['Finally,', 'an', 'hour', 'or', 'two', 'later,', 'my', 'hands', 'are', 'in', 'the', 'palm', 'of', 'the', 'hot', 'gas,', 'easing', 'off', 'his', 'foreskin', 'with', 'steady', 'four', 'fingers', 'and', 'quickly', 'removing', 'it.'], ['I', 'told', 'him', 'to', 'shut', 'up.'], ['I', 'rolled', 'my', 'aching', 'ass', 'at', 'him', 'and', 'he', 'backed', 'away,', 'laughing', 'at', 'my', 'weakness.'], ['I', 'awkwardly', 'kneeled', 'down', 'so', 'that', 'the', 'gray', 'glass', 'domino', 'shaped', 'scratch', 'had', 'good', 'access', 'to', 'my', 'clit.'], ['I', 'simply', 'asked', 'him', 'to', 'try', 'me,', 'calmly', 'saying', '\"', 'Okay', '\"...', 'and', 'to', 'come', 'back', 'and', 'tell', 'me', 'his', 'names,', 'how', 'he', 'had', 'met', 'me,', 'etc.'], ['Once', 'he', 'was', 'standing', 'still', 'again,', 'I', 'lowered', 'myself', 'in', 'his', 'lap.'], ['He', 'says', 'he', 'wants', 'to', 'do', 'it,', 'but', 'my', 'one', 'strong', 'suggestion', 'was', 'to', 'wait', 'for', 'him', 'to', 'come', 'back', 'with']]\n",
      "[('No,', 'NNP'), ('you', 'PRP'), ('will', 'MD'), ('be', 'VB'), ('surprised,', 'JJ'), ('Erika.', 'NNP'), ('\"', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "text_ls = ['The', 'Hotswapp', 'and', 'me', 'shared', 'a', 'pleasant', 'laugh.', '\"', 'Before', 'you', 'shed', 'you', 'can', 'have', 'my', 'guide,', '\"', 'I', 'reminded.', '\"', 'No,', 'you', 'will', 'be', 'surprised,', 'Erika.', '\"', 'Erika', 'nodded.', 'Finally,', 'an', 'hour', 'or', 'two', 'later,', 'my', 'hands', 'are', 'in', 'the', 'palm', 'of', 'the', 'hot', 'gas,', 'easing', 'off', 'his', 'foreskin', 'with', 'steady', 'four', 'fingers', 'and', 'quickly', 'removing', 'it.', 'I', 'told', 'him', 'to', 'shut', 'up.', 'I', 'rolled', 'my', 'aching', 'ass', 'at', 'him', 'and', 'he', 'backed', 'away,', 'laughing', 'at', 'my', 'weakness.', 'I', 'awkwardly', 'kneeled', 'down', 'so', 'that', 'the', 'gray', 'glass', 'domino', 'shaped', 'scratch', 'had', 'good', 'access', 'to', 'my', 'clit.', 'I', 'simply', 'asked', 'him', 'to', 'try', 'me,', 'calmly', 'saying', '\"', 'Okay', '\"...', 'and', 'to', 'come', 'back', 'and', 'tell', 'me', 'his', 'names,', 'how', 'he', 'had', 'met', 'me,', 'etc.', 'Once', 'he', 'was', 'standing', 'still', 'again,', 'I', 'lowered', 'myself', 'in', 'his', 'lap.', 'He', 'says', 'he', 'wants', 'to', 'do', 'it,', 'but', 'my', 'one', 'strong', 'suggestion', 'was', 'to', 'wait', 'for', 'him', 'to', 'come', 'back', 'with']\n",
    "\n",
    "article = ' '.join(text_ls)\n",
    "print(article)\n",
    "ss = nt.sent_tokenize(article)\n",
    "print(ss)\n",
    "tokenized_sent = [sent.split(' ') for sent in ss]\n",
    "print(tokenized_sent)\n",
    "tags = [nltk.pos_tag(sent) for sent in tokenized_sent]\n",
    "print(tags[2])\n",
    "x = []\n",
    "for tag in tags:\n",
    "    x.extend(tag)\n",
    "# print(x)\n",
    "# print(len(x))\n",
    "# print(len(text_ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-scale",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
